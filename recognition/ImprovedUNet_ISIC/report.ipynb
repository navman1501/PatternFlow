{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import PIL as pil\n",
    "import os\n",
    "import PIL\n",
    "import pathlib\n",
    "import glob\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import *\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "#Set to GPU\n",
    "devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(devices[0], True)\n",
    "\n",
    "#Path\n",
    "images_source = pathlib.Path(\"D:\\s4532664\\COMP3710\\ISIC2018_Task1-2_Training_Data\")\n",
    "\n",
    "#Input images\n",
    "input_dir = images_source / \"ISIC2018_Task1-2_Training_Input_x2\\*.jpg\"\n",
    "\n",
    "#Segmentation images (label images)\n",
    "seg_dir = images_source / \"ISIC2018_Task1_Training_GroundTruth_x2\\*.png\"\n",
    "                             \n",
    "#Setup arrays for training, testing and validation datasets\n",
    "X_train = None\n",
    "X_test = None\n",
    "X_valid = None\n",
    "y_train = None\n",
    "y_test = None\n",
    "y_valid = None\n",
    "\n",
    "training = None\n",
    "validation = None\n",
    "testing = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\s4532664\\COMP3710\\ISIC2018_Task1-2_Training_Data\\ISIC2018_Task1-2_Training_Input_x2\\*.jpg\n",
      "D:\\s4532664\\COMP3710\\ISIC2018_Task1-2_Training_Data\\ISIC2018_Task1_Training_GroundTruth_x2\\*.png\n"
     ]
    }
   ],
   "source": [
    "print(input_dir)\n",
    "print(seg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process every filename in the array as an image, using TF functions. \n",
    "#Normalise every image by either 0 or 1 and divide it by 255 for scaling purposes\n",
    "\n",
    "def convert_file_image(input_file, seg_file):\n",
    "   \n",
    "    input_image = tf.io.read_file(input_file)\n",
    "    input_image = tf.image.decode_jpeg(input_image, channels = 1)\n",
    "    input_image = tf.image.resize(input_image, [256, 256])\n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    \n",
    "    seg_image = tf.io.read_file(seg_file)\n",
    "    seg_image = tf.image.decode_png(seg_image, channels = 1)\n",
    "    seg_image = tf.image.resize(seg_image, [256, 256])\n",
    "    seg_image = seg_image == [0, 255]\n",
    "    seg_image = tf.cast(seg_image, tf.float32)\n",
    "    \n",
    "    return input_image, seg_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load images from disk into training, testing and validation arrays (DO DOCSTRING)\n",
    "def load_data(inputdir, segdir):\n",
    "    \n",
    "    xtrain = sorted(glob.glob(str(inputdir)))\n",
    "    ytrain = sorted(glob.glob(str(segdir)))\n",
    "    \n",
    "    xtrain, ytrain = shuffle(xtrain, labels)\n",
    "    \n",
    "    #Split the images into 3 datasets (Training - 50%, Validation - 25%, Testing - 25%)\n",
    "    \n",
    "    half_length = int(len(xtrain)/2)\n",
    "    quarter_length_ceil = int(tf.math.ceil(len(xtrain)/4))\n",
    "    print(quarter_length_ceil)\n",
    "    \n",
    "    global X_test, X_valid, X_train, y_test, y_valid, y_train\n",
    "        \n",
    "    X_test = xtrain[-(quarter_length_ceil-1):]\n",
    "    X_valid = xtrain[half_length:half_length + quarter_length_ceil]\n",
    "    X_train = xtrain[0:half_length]\n",
    "    \n",
    "    y_test = ytrain[-(quarter_length_ceil-1):]\n",
    "    y_valid = ytrain[half_length:half_length + quarter_length_ceil]\n",
    "    y_train = ytrain[0:half_length]\n",
    "     \n",
    "    traindata = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "    validdata = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "    testdata = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
    "    \n",
    "    traindata = traindata.map(convert_file_image)\n",
    "    validdata = validdata.map(convert_file_image)\n",
    "    testdata = testdata.map(convert_file_image)\n",
    "    \n",
    "    return traindata, validdata, testdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "649\n"
     ]
    }
   ],
   "source": [
    "training, validation, testing = load_data(input_dir, seg_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_module_unet(layer, filter_size):\n",
    "    layer = Conv2D(filter_size, (3, 3), padding = 'same')(layer)\n",
    "    layer = LeakyReLU(alpha = 0.3)(layer)\n",
    "    layer = Dropout(0.3)(layer)\n",
    "    layer = Conv2D(filter_size, (3, 3), padding = 'same')(layer)\n",
    "    layer = LeakyReLU(alpha = 0.3)(layer)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def upsample_module_unet(layer, filter_size):\n",
    "    layer = UpSampling2D()(layer)\n",
    "    layer = Conv2D(filter_size, (3, 3), padding = 'same')(layer)\n",
    "    layer = LeakyReLU(alpha = 0.3)(layer)\n",
    "    \n",
    "    return layer\n",
    "    \n",
    "def localisation_module_unet(layer, filter_size):\n",
    "    layer = Conv2D(filter_size, (3, 3), padding = 'same')(layer)\n",
    "    layer = LeakyReLU(alpha = 0.3)(layer)\n",
    "    layer = Conv2D(filter_size, (1, 1), padding = 'same')(layer)\n",
    "    layer = LeakyReLU(alpha = 0.3)(layer)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def segmentation_layer(localise_module_a, localise_module_b, conv_a):\n",
    "    segment_1 = Conv2D(1, (1, 1), padding = 'same')(localise_module_a)\n",
    "    segment_1 = LeakyReLU(alpha = 0.3)(segment_1)\n",
    "\n",
    "    upsample_a = UpSampling2D()(segment_1)\n",
    "    \n",
    "    segment_2 = Conv2D(1, (1, 1), padding = 'same')(localise_module_b)\n",
    "    segment_2 = LeakyReLU(alpha = 0.3)(segment_2)\n",
    "    sum_a = add([upsample_a, segment_2])\n",
    "    \n",
    "    upsample_b = UpSampling2D()(sum_a)\n",
    "    segment_3 = Conv2D(1, (1, 1), padding = 'same')(conv_a)\n",
    "    segment_3 = LeakyReLU(alpha = 0.3)(segment_3)\n",
    "\n",
    "    sum_b = add([upsample_b, segment_3])\n",
    "    \n",
    "    return sum_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model():\n",
    "    inputs = Input((256, 256, 1))\n",
    "    \n",
    "    conv2D_1 = Conv2D(16, (3, 3), padding = 'same')(inputs)\n",
    "    conv2D_1 = LeakyReLU(alpha = 0.3)(conv2D_1)\n",
    "    \n",
    "    cont_1 = context_module_unet(conv2D_1, 16)\n",
    "    sum_1 = add([conv2D_1, cont_1])\n",
    "    \n",
    "    conv2D_2 = Conv2D(32, (3, 3), padding = 'same', strides = 2)(sum_1)\n",
    "    conv2D_2 = LeakyReLU(alpha = 0.3)(conv2D_2)\n",
    "    cont_2 = context_module_unet(conv2D_2, 32)\n",
    "    sum_2 = add([conv2D_2, cont_2])\n",
    "    \n",
    "    conv2D_3 = Conv2D(64, (3, 3), padding = 'same', strides = 2)(sum_2)\n",
    "    conv2D_3 = LeakyReLU(alpha = 0.3)(conv2D_3)\n",
    "    cont_3 = context_module_unet(conv2D_3, 64)\n",
    "    sum_3 = add([conv2D_3, cont_3])\n",
    "    \n",
    "    conv2D_4 = Conv2D(128, (3, 3), padding = 'same', strides = 2)(sum_3)\n",
    "    conv2D_4 = LeakyReLU(alpha = 0.3)(conv2D_4)\n",
    "    cont_4 = context_module_unet(conv2D_4, 128)\n",
    "    sum_4 = add([conv2D_4, cont_4])\n",
    "    \n",
    "    conv2D_5 = Conv2D(256, (3, 3), padding = 'same', strides = 2)(sum_4)\n",
    "    conv2D_5 = LeakyReLU(alpha = 0.3)(conv2D_5)\n",
    "    cont_5 = context_module_unet(conv2D_5, 256)\n",
    "    sum_5 = add([conv2D_5, cont_5])\n",
    "    \n",
    "    upsample_1 = upsample_module_unet(sum_5, 128)\n",
    "    concatenate_1 = concatenate([upsample_1, sum_4])\n",
    "    \n",
    "    localise_1 = localisation_module_unet(concatenate_1, 128)\n",
    "    upsample_2 = upsample_module_unet(localise_1, 64)\n",
    "    concatenate_2 = concatenate([upsample_2, sum_3])\n",
    "    \n",
    "    localise_2 = localisation_module_unet(concatenate_2, 64)\n",
    "    upsample_3 = upsample_module_unet(localise_2, 32)\n",
    "    concatenate_3 = concatenate([upsample_3, sum_2])\n",
    "    \n",
    "    localise_3 = localisation_module_unet(concatenate_3, 32)\n",
    "    upsample_4 = upsample_module_unet(localise_3, 16)\n",
    "    concatenate_4 = concatenate([upsample_4, sum_1])\n",
    "    \n",
    "    conv2D_6 = Conv2D(32, (3, 3), padding = 'same')(concatenate_4)\n",
    "    conv2D_6 = LeakyReLU(alpha = 0.3)(conv2D_6)\n",
    "    \n",
    "    segmentation_1 = segmentation_layer(localise_2, localise_3, conv2D_6)\n",
    "    \n",
    "    conv2D_final = Conv2D(2, (1, 1), activation = 'softmax', padding = 'same')(segmentation_1)\n",
    "\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv2D_final)\n",
    "\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 130 steps, validate for 65 steps\n",
      "Epoch 1/30\n",
      "130/130 [==============================] - 79s 609ms/step - loss: 0.3780 - accuracy: 0.8553 - val_loss: 0.4959 - val_accuracy: 0.7812\n",
      "Epoch 2/30\n",
      "130/130 [==============================] - 77s 592ms/step - loss: 0.3055 - accuracy: 0.8752 - val_loss: 0.4658 - val_accuracy: 0.7948\n",
      "Epoch 3/30\n",
      "130/130 [==============================] - 37s 284ms/step - loss: 0.2653 - accuracy: 0.8999 - val_loss: 0.5600 - val_accuracy: 0.6781\n",
      "Epoch 4/30\n",
      "130/130 [==============================] - 77s 593ms/step - loss: 0.2379 - accuracy: 0.9085 - val_loss: 0.4087 - val_accuracy: 0.8056\n",
      "Epoch 5/30\n",
      "130/130 [==============================] - 47s 361ms/step - loss: 0.2193 - accuracy: 0.9159 - val_loss: 1.0621 - val_accuracy: 0.5655\n",
      "Epoch 6/30\n",
      "130/130 [==============================] - 47s 360ms/step - loss: 0.2074 - accuracy: 0.9202 - val_loss: 0.5856 - val_accuracy: 0.7977\n",
      "Epoch 7/30\n",
      "130/130 [==============================] - 77s 592ms/step - loss: 0.1990 - accuracy: 0.9236 - val_loss: 2.7378 - val_accuracy: 0.4690\n",
      "Epoch 8/30\n",
      "130/130 [==============================] - 47s 361ms/step - loss: 0.1821 - accuracy: 0.9302 - val_loss: 0.2023 - val_accuracy: 0.9288\n",
      "Epoch 9/30\n",
      " 33/130 [======>.......................] - ETA: 1:11 - loss: 0.1609 - accuracy: 0.9361"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-8b50a9b76727>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munet_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = unet_model()\n",
    "\n",
    "results = model.fit(x=training.batch(10), epochs = 30, validation_data = validation.batch(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results.history['accuracy'], label='Training data accuracy')\n",
    "plt.plot(results.history['val_accuracy'], label = 'Test data accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(x=testing.batch(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
